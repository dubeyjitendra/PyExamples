{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigendecomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Matrix decompositions are a useful tool for reducing a matrix to their constituent parts in\n",
    "order to simplify a range of more complex operations. Perhaps the most used type of matrix\n",
    "decomposition is the eigendecomposition that decomposes a matrix into eigenvectors and\n",
    "eigenvalues\n",
    "\n",
    "This decomposition also plays a role in methods used in machine learning, such\n",
    "as in the Principal Component Analysis method or PCA.\n",
    "\n",
    "1. Eigendecomposition of a Matrix\n",
    "2. Eigenvectors and Eigenvalues\n",
    "3. Calculation of Eigendecomposition\n",
    "4. Confirm an Eigenvector and Eigenvalue\n",
    "5. Reconstruct Matrix\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigendecomposition of a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Eigendecomposition of a matrix is a type of decomposition that involves decomposing a square\n",
    "matrix into a set of eigenvectors and eigenvalues.\n",
    "\n",
    "One of the most widely used kinds of matrix decomposition is called eigendecomposition, \n",
    "in which we decompose a matrix into a set of eigenvectors and eigenvalues.\n",
    "\n",
    "Av = λv\n",
    "\n",
    "This is called the eigenvalue equation, where A is the parent square matrix that we are\n",
    "decomposing, v is the eigenvector of the matrix, and λ is the lowercase Greek letter lambda and\n",
    "represents the eigenvalue scalar. \n",
    "\n",
    "\n",
    "A matrix could have one eigenvector and eigenvalue for each dimension of the parent matrix.\n",
    "Not all square matrices can be decomposed into eigenvectors and eigenvalues, and some can\n",
    "only be decomposed in a way that requires complex numbers. The parent matrix can be shown\n",
    "to be a product of the eigenvectors and eigenvalues\n",
    "\n",
    "A = QΛQT(T is Superscript)\n",
    "\n",
    "Where Q is a matrix comprised of the eigenvectors, Λ is the uppercase Greek letter lambda\n",
    "and is the diagonal matrix comprised of the eigenvalues, and QT\n",
    "is the transpose of the matrix\n",
    "comprised of the eigenvector\n",
    "\n",
    "\n",
    "\n",
    "However, we often want to decompose matrices into their eigenvalues and eigenvectors.\n",
    "Doing so can help us to analyze certain properties of the matrix, much as decomposing\n",
    "an integer into its prime factors can help us understand the behavior of that integer\n",
    "\n",
    "— Page 43, Deep Learning, 2016.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Very impotant\n",
    "\n",
    "\"\"\"Eigen is not a name, e.g. the method is not named after “Eigen”; eigen (pronounced\n",
    "eye-gan) is a German word that means own or innate, as in belonging to the parent matrix. A\n",
    "decomposition operation does not result in a compression of the matrix; instead, it breaks it\n",
    "down into constituent parts to make certain operations on the matrix easier to perform. Like\n",
    "other matrix decomposition methods, Eigendecomposition is used as an element to simplify the\n",
    "calculation of other more complex matrix operations\"\"\"\n",
    "\n",
    "## Uses of Eigendecomposition in Machine Learning\n",
    "\"\"\"Eigendecomposition can also be used to calculate the principal components of a matrix in the\n",
    "Principal Component Analysis method or PCA that can be used to reduce the dimensionality\n",
    "of data in machine learning.\"\"\"\n",
    "\n",
    "\n",
    "# Quote\n",
    "\"\"\"Almost all vectors change direction, when they are multiplied by A. Certain\n",
    "exceptional vectors x are in the same direction as Ax. Those are the “eigenvectors”.\n",
    "Multiply an eigenvector by A, and the vector Ax is the number λ times the original\n",
    "x. [...] The eigenvalue λ tells whether the special vector x is stretched or shrunk or\n",
    "reversed or left unchanged — when it is multiplied by A\n",
    "                                    — Page 289, Introduction to Linear Algebra, Fifth Edition, 2016.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvectors and Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Eigenvectors are unit vectors, which means that their length or magnitude is equal to 1.0. They\n",
    "are often referred as right vectors, which simply means a column vector (as opposed to a row\n",
    "vector or a left vector).A right-vector is a vector as we understand them\"\"\"\n",
    "\n",
    "\"\"\"Eigenvalues are coefficients applied to eigenvectors that give the vectors their length or magnitude\"\"\"\n",
    "\n",
    "\"\"\"For example,\n",
    "a negative eigenvalue may reverse the direction of the eigenvector as part of scaling it. A matrix\n",
    "that has only positive eigenvalues is referred to as a positive definite matrix, whereas if the\n",
    "eigenvalues are all negative, it is referred to as a negative definite matrix\"\"\"\n",
    "\n",
    "\"\"\"Calculation of Eigendecomposition\"\"\"\n",
    "\n",
    "\"\"\"An eigendecomposition is calculated on a square matrix using an efficient iterative algorithm, of\n",
    "which we will not go into the details. Often an eigenvalue is found first, then an eigenvector is\n",
    "found to solve the equation as a set of coefficients. The eigendecomposition can be calculated in\n",
    "NumPy using the eig() function. The example below first defines a 3 × 3 square matrix. The\n",
    "eigendecomposition is calculated on the matrix returning the eigenvalues and eigenvectors\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "values============= [ 1.61168440e+01 -1.11684397e+00 -1.30367773e-15]\n",
      "vectors============ [[-0.23197069 -0.78583024  0.40824829]\n",
      " [-0.52532209 -0.08675134 -0.81649658]\n",
      " [-0.8186735   0.61232756  0.40824829]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Running the example first prints the defined matrix, followed by the eigenvalues and the\\neigenvectors. More specifically, the eigenvectors are the right-hand side eigenvectors and are\\nnormalized to unit length.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eigendecomposition\n",
    "from numpy import array\n",
    "from numpy.linalg import eig\n",
    "# define matrix\n",
    "A = array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "print(A)\n",
    "# factorize\n",
    "values, vectors = eig(A)\n",
    "print(\"values=============\",values)\n",
    "print(\"vectors============\",vectors)\n",
    "\"\"\"Running the example first prints the defined matrix, followed by the eigenvalues and the\n",
    "eigenvectors. More specifically, the eigenvectors are the right-hand side eigenvectors and are\n",
    "normalized to unit length.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm an Eigenvector and Eigenvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We can confirm that a vector is indeed an eigenvector of a matrix. We do this by multiplying\n",
    "the candidate eigenvector by the value vector and comparing the result with the eigenvalue.\n",
    "First, we will define a matrix, then calculate the eigenvalues and eigenvectors. We will then test\n",
    "whether the first vector and value are in fact an eigenvalue and eigenvector for the matrix. We\n",
    "know they are, but it is a good exercise.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"The eigenvectors are returned as a matrix with the same dimensions as the parent matrix,\n",
    "where each column is an eigenvector, e.g. the first eigenvector is vectors[:, 0]. Eigenvalues\n",
    "are returned as a list, where value indices in the returned array are paired with eigenvectors\n",
    "by column index, e.g. the first eigenvalue at values[0] is paired with the first eigenvector at\n",
    "vectors[:, 0].\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.73863537  -8.46653421 -13.19443305]\n",
      "[ -3.73863537  -8.46653421 -13.19443305]\n"
     ]
    }
   ],
   "source": [
    "### Example of calculating a confirmation of an eigendecomposition.\n",
    "# confirm eigenvector\n",
    "from numpy import array\n",
    "from numpy.linalg import eig\n",
    "# define matrix\n",
    "A = array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "# factorize\n",
    "values, vectors = eig(A)\n",
    "# confirm first eigenvector\n",
    "B = A.dot(vectors[:, 0])\n",
    "print(B)\n",
    "C = vectors[:, 0] * values[0]\n",
    "print(C)\n",
    "\n",
    "\"\"\"The example multiplies the original matrix with the first eigenvector and compares it to the\n",
    "first eigenvector multiplied by the first eigenvalue. Running the example prints the results of\n",
    "these two multiplications that show the same resulting vector, as we would expect.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We can reverse the process and reconstruct the original matrix given only the eigenvectors and\n",
    "eigenvalues. First, the list of eigenvectors must be taken together as a matrix, where each vector\n",
    "becomes a row. The eigenvalues need to be arranged into a diagonal matrix. The NumPy\n",
    "diag() function can be used for this. Next, we need to calculate the inverse of the eigenvector\n",
    "matrix, which we can achieve with the inv() NumPy function. Finally, these elements need to\n",
    "be multiplied together with the dot() function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The example calculates the eigenvalues and eigenvectors again and uses them to reconstruct\\nthe original matrix. Running the example first prints the original matrix, then the matrix\\nreconstructed from eigenvalues and eigenvectors matching the original matrix.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct matrix\n",
    "from numpy import diag\n",
    "from numpy.linalg import inv\n",
    "from numpy import array\n",
    "from numpy.linalg import eig\n",
    "# define matrix\n",
    "A = array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "print(A)\n",
    "# factorize\n",
    "values, vectors = eig(A)\n",
    "# create matrix from eigenvectors\n",
    "Q = vectors\n",
    "# create inverse of eigenvectors matrix\n",
    "R = inv(Q)\n",
    "# create diagonal matrix from eigenvalues\n",
    "L = diag(values)\n",
    "# reconstruct the original matrix\n",
    "B = Q.dot(L).dot(R)\n",
    "print(B)\n",
    "\n",
    "\"\"\"The example calculates the eigenvalues and eigenvectors again and uses them to reconstruct\n",
    "the original matrix. Running the example first prints the original matrix, then the matrix\n",
    "reconstructed from eigenvalues and eigenvectors matching the original matrix.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
