{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Processing in OpenCV-part-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0H0CvrMuOHT",
        "colab_type": "text"
      },
      "source": [
        "# 1. Changing Colorspaces\n",
        "\n",
        "how to convert images from one color-space to another, like **BGR <-->GRAY, BGR <---> HSV** etc.\n",
        "\n",
        "BGR = Blue Green Red= 3 channel\n",
        "Gray = Gray =1 channel\n",
        "HSV = Hue-Saturation-Value,\n",
        "\n",
        "\n",
        "#####HSV means Hue-Saturation-Value, where the Hue is the color.Saturation is the greyness, so that a Saturation value near 0 means it is dull or grey looking.And Value is the brightness of the pixel.(For a lot more info about HSV and other color spaces, go to HSL and HSV on Wikipedia)\n",
        "\n",
        " following functions:\n",
        "\n",
        "**cv2.cvtColor()**\n",
        "**cv2.inRange()**\n",
        "\n",
        "\n",
        "**There are more than 150 color-space conversion methods available in OpenCV. But we will look into only two which are most widely used ones,** **BGR <-->GRAY, BGR <---> HSV**\n",
        "\n",
        "\n",
        "\n",
        "For color conversion, we use the function **cv2.cvtColor(input_image, flag)** where flag determines the type of conversion.\n",
        "\n",
        "**BGR <-->GRAY** conversion we use the flags **cv2.COLOR_BGR2GRAY**\n",
        "\n",
        "**BGR <---> HSV** conversion we use the flags **cv2.COLOR_BGR2HSV**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E62NgdrxUQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To get other flags, just run following commands \n",
        "import cv2 \n",
        "\n",
        "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrtFnpg-xZaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4675
        },
        "outputId": "a20ff10d-40d9-4495-b677-20ca6431d7f5"
      },
      "source": [
        "flags"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['COLOR_BAYER_BG2BGR',\n",
              " 'COLOR_BAYER_BG2BGRA',\n",
              " 'COLOR_BAYER_BG2BGR_EA',\n",
              " 'COLOR_BAYER_BG2BGR_VNG',\n",
              " 'COLOR_BAYER_BG2GRAY',\n",
              " 'COLOR_BAYER_BG2RGB',\n",
              " 'COLOR_BAYER_BG2RGBA',\n",
              " 'COLOR_BAYER_BG2RGB_EA',\n",
              " 'COLOR_BAYER_BG2RGB_VNG',\n",
              " 'COLOR_BAYER_GB2BGR',\n",
              " 'COLOR_BAYER_GB2BGRA',\n",
              " 'COLOR_BAYER_GB2BGR_EA',\n",
              " 'COLOR_BAYER_GB2BGR_VNG',\n",
              " 'COLOR_BAYER_GB2GRAY',\n",
              " 'COLOR_BAYER_GB2RGB',\n",
              " 'COLOR_BAYER_GB2RGBA',\n",
              " 'COLOR_BAYER_GB2RGB_EA',\n",
              " 'COLOR_BAYER_GB2RGB_VNG',\n",
              " 'COLOR_BAYER_GR2BGR',\n",
              " 'COLOR_BAYER_GR2BGRA',\n",
              " 'COLOR_BAYER_GR2BGR_EA',\n",
              " 'COLOR_BAYER_GR2BGR_VNG',\n",
              " 'COLOR_BAYER_GR2GRAY',\n",
              " 'COLOR_BAYER_GR2RGB',\n",
              " 'COLOR_BAYER_GR2RGBA',\n",
              " 'COLOR_BAYER_GR2RGB_EA',\n",
              " 'COLOR_BAYER_GR2RGB_VNG',\n",
              " 'COLOR_BAYER_RG2BGR',\n",
              " 'COLOR_BAYER_RG2BGRA',\n",
              " 'COLOR_BAYER_RG2BGR_EA',\n",
              " 'COLOR_BAYER_RG2BGR_VNG',\n",
              " 'COLOR_BAYER_RG2GRAY',\n",
              " 'COLOR_BAYER_RG2RGB',\n",
              " 'COLOR_BAYER_RG2RGBA',\n",
              " 'COLOR_BAYER_RG2RGB_EA',\n",
              " 'COLOR_BAYER_RG2RGB_VNG',\n",
              " 'COLOR_BGR2BGR555',\n",
              " 'COLOR_BGR2BGR565',\n",
              " 'COLOR_BGR2BGRA',\n",
              " 'COLOR_BGR2GRAY',\n",
              " 'COLOR_BGR2HLS',\n",
              " 'COLOR_BGR2HLS_FULL',\n",
              " 'COLOR_BGR2HSV',\n",
              " 'COLOR_BGR2HSV_FULL',\n",
              " 'COLOR_BGR2LAB',\n",
              " 'COLOR_BGR2LUV',\n",
              " 'COLOR_BGR2Lab',\n",
              " 'COLOR_BGR2Luv',\n",
              " 'COLOR_BGR2RGB',\n",
              " 'COLOR_BGR2RGBA',\n",
              " 'COLOR_BGR2XYZ',\n",
              " 'COLOR_BGR2YCR_CB',\n",
              " 'COLOR_BGR2YCrCb',\n",
              " 'COLOR_BGR2YUV',\n",
              " 'COLOR_BGR2YUV_I420',\n",
              " 'COLOR_BGR2YUV_IYUV',\n",
              " 'COLOR_BGR2YUV_YV12',\n",
              " 'COLOR_BGR5552BGR',\n",
              " 'COLOR_BGR5552BGRA',\n",
              " 'COLOR_BGR5552GRAY',\n",
              " 'COLOR_BGR5552RGB',\n",
              " 'COLOR_BGR5552RGBA',\n",
              " 'COLOR_BGR5652BGR',\n",
              " 'COLOR_BGR5652BGRA',\n",
              " 'COLOR_BGR5652GRAY',\n",
              " 'COLOR_BGR5652RGB',\n",
              " 'COLOR_BGR5652RGBA',\n",
              " 'COLOR_BGRA2BGR',\n",
              " 'COLOR_BGRA2BGR555',\n",
              " 'COLOR_BGRA2BGR565',\n",
              " 'COLOR_BGRA2GRAY',\n",
              " 'COLOR_BGRA2RGB',\n",
              " 'COLOR_BGRA2RGBA',\n",
              " 'COLOR_BGRA2YUV_I420',\n",
              " 'COLOR_BGRA2YUV_IYUV',\n",
              " 'COLOR_BGRA2YUV_YV12',\n",
              " 'COLOR_BayerBG2BGR',\n",
              " 'COLOR_BayerBG2BGRA',\n",
              " 'COLOR_BayerBG2BGR_EA',\n",
              " 'COLOR_BayerBG2BGR_VNG',\n",
              " 'COLOR_BayerBG2GRAY',\n",
              " 'COLOR_BayerBG2RGB',\n",
              " 'COLOR_BayerBG2RGBA',\n",
              " 'COLOR_BayerBG2RGB_EA',\n",
              " 'COLOR_BayerBG2RGB_VNG',\n",
              " 'COLOR_BayerGB2BGR',\n",
              " 'COLOR_BayerGB2BGRA',\n",
              " 'COLOR_BayerGB2BGR_EA',\n",
              " 'COLOR_BayerGB2BGR_VNG',\n",
              " 'COLOR_BayerGB2GRAY',\n",
              " 'COLOR_BayerGB2RGB',\n",
              " 'COLOR_BayerGB2RGBA',\n",
              " 'COLOR_BayerGB2RGB_EA',\n",
              " 'COLOR_BayerGB2RGB_VNG',\n",
              " 'COLOR_BayerGR2BGR',\n",
              " 'COLOR_BayerGR2BGRA',\n",
              " 'COLOR_BayerGR2BGR_EA',\n",
              " 'COLOR_BayerGR2BGR_VNG',\n",
              " 'COLOR_BayerGR2GRAY',\n",
              " 'COLOR_BayerGR2RGB',\n",
              " 'COLOR_BayerGR2RGBA',\n",
              " 'COLOR_BayerGR2RGB_EA',\n",
              " 'COLOR_BayerGR2RGB_VNG',\n",
              " 'COLOR_BayerRG2BGR',\n",
              " 'COLOR_BayerRG2BGRA',\n",
              " 'COLOR_BayerRG2BGR_EA',\n",
              " 'COLOR_BayerRG2BGR_VNG',\n",
              " 'COLOR_BayerRG2GRAY',\n",
              " 'COLOR_BayerRG2RGB',\n",
              " 'COLOR_BayerRG2RGBA',\n",
              " 'COLOR_BayerRG2RGB_EA',\n",
              " 'COLOR_BayerRG2RGB_VNG',\n",
              " 'COLOR_COLORCVT_MAX',\n",
              " 'COLOR_GRAY2BGR',\n",
              " 'COLOR_GRAY2BGR555',\n",
              " 'COLOR_GRAY2BGR565',\n",
              " 'COLOR_GRAY2BGRA',\n",
              " 'COLOR_GRAY2RGB',\n",
              " 'COLOR_GRAY2RGBA',\n",
              " 'COLOR_HLS2BGR',\n",
              " 'COLOR_HLS2BGR_FULL',\n",
              " 'COLOR_HLS2RGB',\n",
              " 'COLOR_HLS2RGB_FULL',\n",
              " 'COLOR_HSV2BGR',\n",
              " 'COLOR_HSV2BGR_FULL',\n",
              " 'COLOR_HSV2RGB',\n",
              " 'COLOR_HSV2RGB_FULL',\n",
              " 'COLOR_LAB2BGR',\n",
              " 'COLOR_LAB2LBGR',\n",
              " 'COLOR_LAB2LRGB',\n",
              " 'COLOR_LAB2RGB',\n",
              " 'COLOR_LBGR2LAB',\n",
              " 'COLOR_LBGR2LUV',\n",
              " 'COLOR_LBGR2Lab',\n",
              " 'COLOR_LBGR2Luv',\n",
              " 'COLOR_LRGB2LAB',\n",
              " 'COLOR_LRGB2LUV',\n",
              " 'COLOR_LRGB2Lab',\n",
              " 'COLOR_LRGB2Luv',\n",
              " 'COLOR_LUV2BGR',\n",
              " 'COLOR_LUV2LBGR',\n",
              " 'COLOR_LUV2LRGB',\n",
              " 'COLOR_LUV2RGB',\n",
              " 'COLOR_Lab2BGR',\n",
              " 'COLOR_Lab2LBGR',\n",
              " 'COLOR_Lab2LRGB',\n",
              " 'COLOR_Lab2RGB',\n",
              " 'COLOR_Luv2BGR',\n",
              " 'COLOR_Luv2LBGR',\n",
              " 'COLOR_Luv2LRGB',\n",
              " 'COLOR_Luv2RGB',\n",
              " 'COLOR_M_RGBA2RGBA',\n",
              " 'COLOR_RGB2BGR',\n",
              " 'COLOR_RGB2BGR555',\n",
              " 'COLOR_RGB2BGR565',\n",
              " 'COLOR_RGB2BGRA',\n",
              " 'COLOR_RGB2GRAY',\n",
              " 'COLOR_RGB2HLS',\n",
              " 'COLOR_RGB2HLS_FULL',\n",
              " 'COLOR_RGB2HSV',\n",
              " 'COLOR_RGB2HSV_FULL',\n",
              " 'COLOR_RGB2LAB',\n",
              " 'COLOR_RGB2LUV',\n",
              " 'COLOR_RGB2Lab',\n",
              " 'COLOR_RGB2Luv',\n",
              " 'COLOR_RGB2RGBA',\n",
              " 'COLOR_RGB2XYZ',\n",
              " 'COLOR_RGB2YCR_CB',\n",
              " 'COLOR_RGB2YCrCb',\n",
              " 'COLOR_RGB2YUV',\n",
              " 'COLOR_RGB2YUV_I420',\n",
              " 'COLOR_RGB2YUV_IYUV',\n",
              " 'COLOR_RGB2YUV_YV12',\n",
              " 'COLOR_RGBA2BGR',\n",
              " 'COLOR_RGBA2BGR555',\n",
              " 'COLOR_RGBA2BGR565',\n",
              " 'COLOR_RGBA2BGRA',\n",
              " 'COLOR_RGBA2GRAY',\n",
              " 'COLOR_RGBA2M_RGBA',\n",
              " 'COLOR_RGBA2RGB',\n",
              " 'COLOR_RGBA2YUV_I420',\n",
              " 'COLOR_RGBA2YUV_IYUV',\n",
              " 'COLOR_RGBA2YUV_YV12',\n",
              " 'COLOR_RGBA2mRGBA',\n",
              " 'COLOR_XYZ2BGR',\n",
              " 'COLOR_XYZ2RGB',\n",
              " 'COLOR_YCR_CB2BGR',\n",
              " 'COLOR_YCR_CB2RGB',\n",
              " 'COLOR_YCrCb2BGR',\n",
              " 'COLOR_YCrCb2RGB',\n",
              " 'COLOR_YUV2BGR',\n",
              " 'COLOR_YUV2BGRA_I420',\n",
              " 'COLOR_YUV2BGRA_IYUV',\n",
              " 'COLOR_YUV2BGRA_NV12',\n",
              " 'COLOR_YUV2BGRA_NV21',\n",
              " 'COLOR_YUV2BGRA_UYNV',\n",
              " 'COLOR_YUV2BGRA_UYVY',\n",
              " 'COLOR_YUV2BGRA_Y422',\n",
              " 'COLOR_YUV2BGRA_YUNV',\n",
              " 'COLOR_YUV2BGRA_YUY2',\n",
              " 'COLOR_YUV2BGRA_YUYV',\n",
              " 'COLOR_YUV2BGRA_YV12',\n",
              " 'COLOR_YUV2BGRA_YVYU',\n",
              " 'COLOR_YUV2BGR_I420',\n",
              " 'COLOR_YUV2BGR_IYUV',\n",
              " 'COLOR_YUV2BGR_NV12',\n",
              " 'COLOR_YUV2BGR_NV21',\n",
              " 'COLOR_YUV2BGR_UYNV',\n",
              " 'COLOR_YUV2BGR_UYVY',\n",
              " 'COLOR_YUV2BGR_Y422',\n",
              " 'COLOR_YUV2BGR_YUNV',\n",
              " 'COLOR_YUV2BGR_YUY2',\n",
              " 'COLOR_YUV2BGR_YUYV',\n",
              " 'COLOR_YUV2BGR_YV12',\n",
              " 'COLOR_YUV2BGR_YVYU',\n",
              " 'COLOR_YUV2GRAY_420',\n",
              " 'COLOR_YUV2GRAY_I420',\n",
              " 'COLOR_YUV2GRAY_IYUV',\n",
              " 'COLOR_YUV2GRAY_NV12',\n",
              " 'COLOR_YUV2GRAY_NV21',\n",
              " 'COLOR_YUV2GRAY_UYNV',\n",
              " 'COLOR_YUV2GRAY_UYVY',\n",
              " 'COLOR_YUV2GRAY_Y422',\n",
              " 'COLOR_YUV2GRAY_YUNV',\n",
              " 'COLOR_YUV2GRAY_YUY2',\n",
              " 'COLOR_YUV2GRAY_YUYV',\n",
              " 'COLOR_YUV2GRAY_YV12',\n",
              " 'COLOR_YUV2GRAY_YVYU',\n",
              " 'COLOR_YUV2RGB',\n",
              " 'COLOR_YUV2RGBA_I420',\n",
              " 'COLOR_YUV2RGBA_IYUV',\n",
              " 'COLOR_YUV2RGBA_NV12',\n",
              " 'COLOR_YUV2RGBA_NV21',\n",
              " 'COLOR_YUV2RGBA_UYNV',\n",
              " 'COLOR_YUV2RGBA_UYVY',\n",
              " 'COLOR_YUV2RGBA_Y422',\n",
              " 'COLOR_YUV2RGBA_YUNV',\n",
              " 'COLOR_YUV2RGBA_YUY2',\n",
              " 'COLOR_YUV2RGBA_YUYV',\n",
              " 'COLOR_YUV2RGBA_YV12',\n",
              " 'COLOR_YUV2RGBA_YVYU',\n",
              " 'COLOR_YUV2RGB_I420',\n",
              " 'COLOR_YUV2RGB_IYUV',\n",
              " 'COLOR_YUV2RGB_NV12',\n",
              " 'COLOR_YUV2RGB_NV21',\n",
              " 'COLOR_YUV2RGB_UYNV',\n",
              " 'COLOR_YUV2RGB_UYVY',\n",
              " 'COLOR_YUV2RGB_Y422',\n",
              " 'COLOR_YUV2RGB_YUNV',\n",
              " 'COLOR_YUV2RGB_YUY2',\n",
              " 'COLOR_YUV2RGB_YUYV',\n",
              " 'COLOR_YUV2RGB_YV12',\n",
              " 'COLOR_YUV2RGB_YVYU',\n",
              " 'COLOR_YUV420P2BGR',\n",
              " 'COLOR_YUV420P2BGRA',\n",
              " 'COLOR_YUV420P2GRAY',\n",
              " 'COLOR_YUV420P2RGB',\n",
              " 'COLOR_YUV420P2RGBA',\n",
              " 'COLOR_YUV420SP2BGR',\n",
              " 'COLOR_YUV420SP2BGRA',\n",
              " 'COLOR_YUV420SP2GRAY',\n",
              " 'COLOR_YUV420SP2RGB',\n",
              " 'COLOR_YUV420SP2RGBA',\n",
              " 'COLOR_YUV420p2BGR',\n",
              " 'COLOR_YUV420p2BGRA',\n",
              " 'COLOR_YUV420p2GRAY',\n",
              " 'COLOR_YUV420p2RGB',\n",
              " 'COLOR_YUV420p2RGBA',\n",
              " 'COLOR_YUV420sp2BGR',\n",
              " 'COLOR_YUV420sp2BGRA',\n",
              " 'COLOR_YUV420sp2GRAY',\n",
              " 'COLOR_YUV420sp2RGB',\n",
              " 'COLOR_YUV420sp2RGBA',\n",
              " 'COLOR_mRGBA2RGBA']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PbZfyfAxLRD",
        "colab_type": "text"
      },
      "source": [
        "## Object Tracking\n",
        "\n",
        "#### how to convert BGR image to HSV, we can use this to extract a colored object. In HSV, it is more easier to represent a color than RGB color-space. In our application, we will try to extract a blue colored object. So here is the method:\n",
        "\n",
        "1. Take each frame of the video\n",
        "\n",
        "2. Convert from BGR to HSV color-space\n",
        "\n",
        "3. We threshold the HSV image for a range of blue color\n",
        "\n",
        "4. Now extract the blue object alone, we can do whatever on that image we want.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkddmnodyvuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import google libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnUE-dGfy5c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path=(\"/content/drive/My Drive/Computer vision/images/lena.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfkzGjTmzpoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read images RGB =1\n",
        "\n",
        "frame = cv2.imread(image_path,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkpygC0IymlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Convert BGR to HSV\n",
        " \n",
        " hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OahUsv2Jz8vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpFcAVPs0Kpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read images gray =0 if image is gray scale set flag =0 other than set -1 after that we would convert into gray image\n",
        "\n",
        "frame2 = cv2.imread(image_path,-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT9NXTox0EuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Convert BGR to GRAY\n",
        "  \n",
        "  gray_image = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRA3gzbr0563",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d776e874-f5c0-4ab3-f310-fec01fc3f053"
      },
      "source": [
        "gray_image"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[163, 162, 161, ..., 170, 154, 130],\n",
              "       [162, 162, 162, ..., 173, 155, 126],\n",
              "       [162, 162, 163, ..., 170, 155, 128],\n",
              "       ...,\n",
              "       [ 43,  42,  51, ..., 103, 101,  99],\n",
              "       [ 41,  42,  55, ..., 103, 105, 106],\n",
              "       [ 42,  44,  57, ..., 102, 106, 109]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e55mtrAJyQ2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while(1):\n",
        "\n",
        "    # Take each frame\n",
        "    #_, frame = cap.read()\n",
        "\n",
        "    # Convert BGR to HSV\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # define range of blue color in HSV\n",
        "    lower_blue = np.array([110,50,50])\n",
        "    upper_blue = np.array([130,255,255])\n",
        "\n",
        "    # Threshold the HSV image to get only blue colors\n",
        "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "\n",
        "    # Bitwise-AND mask and original image\n",
        "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
        "\n",
        "    cv2.imshow('frame',frame)\n",
        "    cv2.imshow('mask',mask)\n",
        "    cv2.imshow('res',res)\n",
        "    k = cv2.waitKey(5) & 0xFF\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggCjDBMq3aHA",
        "colab_type": "text"
      },
      "source": [
        "# Geometric Transformations of Images\n",
        "\n",
        "geometric **transformation** to images like translation, rotation, affine transformation etc.\n",
        "\n",
        "1- Transformations\n",
        "\n",
        "2- affine transformation\n",
        "\n",
        "3- Perspective Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAxEicz84fUp",
        "colab_type": "text"
      },
      "source": [
        "## 1- Transformations\n",
        "\n",
        "\n",
        "  # 1.Scaling\n",
        "  \n",
        "  Scaling is just resizing of the image.\n",
        "  \n",
        "  \n",
        " OpenCV comes with a function cv2.resize() for this purpose. The size of the image can be specified manually, or you can specify the scaling factor. Different interpolation methods are used. Preferable interpolation methods are cv2.INTER_AREA for shrinking and cv2.INTER_CUBIC (slow) & cv2.INTER_LINEAR for zooming. By default, interpolation method used is cv2.INTER_LINEAR for all resizing purposes. You can resize an input image either of following methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxTxxrlx5IVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread(image_path)\n",
        "\n",
        "res = cv2.resize(img,None,fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "#OR\n",
        "\n",
        "height, width = img.shape[:2]\n",
        "res = cv2.resize(img,(2*width, 2*height), interpolation = cv2.INTER_CUBIC)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpyjmN1u5fZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2125fba-b1c1-45bf-bf19-5a4b73821cfc"
      },
      "source": [
        "height, width"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE8vDAjP51nN",
        "colab_type": "text"
      },
      "source": [
        "# 2. Translation\n",
        "\n",
        "\n",
        "Translation is the shifting of objectâ€™s location. If you know the shift in (x,y) direction, let it be (t_x,t_y), you can create the transformation matrix \\textbf{M} as follows:\n",
        "\n",
        "M = \\begin{bmatrix} 1 & 0 & t_x \\\\ 0 & 1 & t_y  \\end{bmatrix}\n",
        "\n",
        "You can take make it into a Numpy array of type np.float32 and pass it into cv2.warpAffine() function. See below example for a shift of (100,50):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdZuPYvf5vK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(image_path,0)\n",
        "rows,cols = img.shape\n",
        "\n",
        "M = np.float32([[1,0,100],[0,1,50]])\n",
        "dst = cv2.warpAffine(img,M,(cols,rows))\n",
        "\n",
        "cv2.imshow('img',dst)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcVNxxJe6e98",
        "colab_type": "text"
      },
      "source": [
        "See the result below:\n",
        "\n",
        "![alt text](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/translation.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as9V2JwN70EA",
        "colab_type": "text"
      },
      "source": [
        "# Rotation\n",
        "\n",
        "Rotation of an image for an angle \\theta is achieved by the transformation matrix of the form\n",
        "\n",
        "M = \\begin{bmatrix} cos\\theta & -sin\\theta \\\\ sin\\theta & cos\\theta   \\end{bmatrix}\n",
        "\n",
        "But OpenCV provides scaled rotation with adjustable center of rotation so that you can rotate at any location you prefer. Modified transformation matrix is given by\n",
        "\n",
        "\\begin{bmatrix} \\alpha &  \\beta & (1- \\alpha )  \\cdot center.x -  \\beta \\cdot center.y \\\\ - \\beta &  \\alpha &  \\beta \\cdot center.x + (1- \\alpha )  \\cdot center.y \\end{bmatrix}\n",
        "\n",
        "where:\n",
        "\n",
        "\\begin{array}{l} \\alpha =  scale \\cdot \\cos \\theta , \\\\ \\beta =  scale \\cdot \\sin \\theta \\end{array}\n",
        "\n",
        "To find this transformation matrix, OpenCV provides a function, cv2.getRotationMatrix2D. Check below example which rotates the image by 90 degree with respect to center without any scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCMAg5wd6Y45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread(image_path,0)\n",
        "rows,cols = img.shape\n",
        "\n",
        "M = cv2.getRotationMatrix2D((cols/2,rows/2),90,1)\n",
        "dst = cv2.warpAffine(img,M,(cols,rows))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr3bKGRc8Goe",
        "colab_type": "text"
      },
      "source": [
        "see the result:\n",
        "\n",
        "![alt text](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/rotation.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OhBy-Vw8VmS",
        "colab_type": "text"
      },
      "source": [
        "# 2. Affine Transformation\n",
        "\n",
        "\n",
        "In affine transformation, all parallel lines in the original image will still be parallel in the output image. To find the transformation matrix, we need three points from input image and their corresponding locations in output image. Then cv2.getAffineTransform will create a 2x3 matrix which is to be passed to cv2.warpAffine.\n",
        "\n",
        "Check below example, and also look at the points I selected (which are marked in Green color):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYF3M8hB8ewb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread(image_path)\n",
        "rows,cols,ch = img.shape\n",
        "\n",
        "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
        "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
        "\n",
        "M = cv2.getAffineTransform(pts1,pts2)\n",
        "\n",
        "dst = cv2.warpAffine(img,M,(cols,rows))\n",
        "\n",
        "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
        "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TgEmtHD8s_A",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/affine.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPP_hcki8wHX",
        "colab_type": "text"
      },
      "source": [
        "# 3. Perspective Transformation\n",
        "\n",
        "\n",
        "For perspective transformation, you need a 3x3 transformation matrix. Straight lines will remain straight even after the transformation. To find this transformation matrix, you need 4 points on the input image and corresponding points on the output image. Among these 4 points, 3 of them should not be collinear. Then transformation matrix can be found by the function cv2.getPerspectiveTransform. Then apply cv2.warpPerspective with this 3x3 transformation matrix.\n",
        "\n",
        "See the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtM_Hoqj87pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread(image_path)\n",
        "rows,cols,ch = img.shape\n",
        "\n",
        "pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
        "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
        "\n",
        "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "\n",
        "dst = cv2.warpPerspective(img,M,(300,300))\n",
        "\n",
        "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
        "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eok0pQCd9FMu",
        "colab_type": "text"
      },
      "source": [
        "result:\n",
        "\n",
        "![alt text](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/perspective.jpg)"
      ]
    }
  ]
}