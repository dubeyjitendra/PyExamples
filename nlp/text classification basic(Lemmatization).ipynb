{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Lemmatization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simpler forms, a method that switches any kind of a word to its base root mode is called Lemmatization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization\n",
    "In English words (Other language as well), same word may have different form such as \"affected\", \"affects\" and \"affect\".  To have a smaller size vocabulary and better representation on NLP problem, we want to have a single word to represent \"\", \"\" in some scenarios. \n",
    "In this article, we will go through some libraries to work on lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"Lemmatisation (or lemmatization) in linguistics is the process of grouping together \\\n",
    "the inflected forms of a word so they can be analysed as a single item, identified by the word's \\\n",
    "lemma, or dictionary form.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "print('spaCy Version: %s' % (spacy.__version__))\n",
    "spacy_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = spacy_nlp(article)\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "print('Original Article: %s' % (article))\n",
    "print()\n",
    "\n",
    "for token in doc:\n",
    "    if token.text != token.lemma_:\n",
    "        print('Original : %s, New: %s' % (token.text, token.lemma_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "print('NLTK Version: %s' % (nltk.__version__))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(article)\n",
    "\n",
    "print('Original Article: %s' % (article))\n",
    "print()\n",
    "\n",
    "for token in tokens:\n",
    "    lemmatized_token = wordnet_lemmatizer.lemmatize(token)\n",
    "    \n",
    "    if token != lemmatized_token:\n",
    "        print('Original : %s, New: %s' % (token, lemmatized_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
