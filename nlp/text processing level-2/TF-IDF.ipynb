{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency and Inverse Docuement Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition :\n",
    "    \n",
    "how important a word is to a document in a collection or corpus.\n",
    "\n",
    "Or \n",
    "\n",
    "How many word is to a document in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency (TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first understand Term Frequent (TF). It is a measure of how frequently a term, t, appears in a document, d:\n",
    "    \n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/tf-300x41.jpg\" width=\"550px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in the numerator, n is the number of times the term “t” appears in the document “d”. Thus, each document and term would have its own TF value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to calculate the TF for Review:\n",
    "\n",
    "Review 1: This movie is very scary and long\n",
    "    \n",
    "Review 2: This movie is not scary and is slow\n",
    "    \n",
    "Review 3: This movie is spooky and good\n",
    "\n",
    "\n",
    "Vocabulary: ‘This’, ‘movie’, ‘is’, ‘very’, ‘scary’, ‘and’, ‘long’, ‘not’,  ‘slow’, ‘spooky’,  ‘good’\n",
    "\n",
    "Review2:\n",
    "TF(‘movie’) = 1/8\n",
    "TF(‘is’) = 2/8 = 1/4\n",
    "TF(‘very’) = 0/8 = 0\n",
    "TF(‘scary’) = 1/8\n",
    "TF(‘and’) = 1/8\n",
    "TF(‘long’) = 0/8 = 0\n",
    "TF(‘not’) = 1/8\n",
    "TF(‘slow’) = 1/8\n",
    "TF( ‘spooky’) = 0/8 = 0\n",
    "TF(‘good’) = 0/8 = 0\n",
    "\n",
    "\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/TF-matrix-1.png\" width=\"550px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/idf-300x44.jpg\" width=\"550px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the IDF values for the all the words in Review 2:\n",
    "    \n",
    "IDF(‘this’) =  log(number of documents/number of documents containing the word ‘this’) = log(3/3) = log(1) = 0\n",
    "\n",
    "Similarly,\n",
    "\n",
    "IDF(‘movie’, ) = log(3/3) = 0\n",
    "IDF(‘is’) = log(3/3) = 0\n",
    "IDF(‘not’) = log(3/1) = log(3) = 0.48\n",
    "IDF(‘scary’) = log(3/2) = 0.18\n",
    "IDF(‘and’) = log(3/3) = 0\n",
    "IDF(‘slow’) = log(3/1) = 0.48\n",
    "\n",
    "We can calculate the IDF values for each word like this. Thus, the IDF values for the entire vocabulary would be:\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/IDF-matrix.png\" width=\"550px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we see that words like “is”, “this”, “and”, etc., are reduced to 0 and have little importance; while words like “scary”, “long”, “good”, etc. are words with more importance and thus have a higher value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/tf_idf.jpg\" width=\"550px\" />\n",
    "\n",
    "We can now calculate the TF-IDF score for every word in Review 2:\n",
    "\n",
    "TF-IDF(‘this’, Review 2) = TF(‘this’, Review 2) * IDF(‘this’) = 1/8 * 0 = 0\n",
    "\n",
    "Similarly,\n",
    "\n",
    "TF-IDF(‘movie’, Review 2) = 1/8 * 0 = 0\n",
    "TF-IDF(‘is’, Review 2) = 1/4 * 0 = 0\n",
    "TF-IDF(‘not’, Review 2) = 1/8 * 0.48 = 0.06\n",
    "TF-IDF(‘scary’, Review 2) = 1/8 * 0.18 = 0.023\n",
    "TF-IDF(‘and’, Review 2) = 1/8 * 0 = 0\n",
    "TF-IDF(‘slow’, Review 2) = 1/8 * 0.48 = 0.06\n",
    "\n",
    "Similarly, we can calculate the TF-IDF scores for all the words with respect to all the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/TF_IDF-matrix.png\" width=\"550px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF also gives larger values for less frequent words and is high when both IDF and TF values are high i.e the word is rare in all the documents combined but frequent in a single document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF(w) = (Number of times term w appears in a document) / (Total number of terms in the document)\n",
    "\n",
    "IDF(w) = log_e(Total number of documents / Number of documents with term w in it)\n",
    "\n",
    "Consider a document containing 100 words wherein the word 'Cauvery' appears 3 times.\n",
    "\n",
    "The term frequency (tf) for 'Cauvery' is then TF = (3 / 100) = 0.03.\n",
    "\n",
    "Now, assume we have 10 million documents and the word 'Cauvery' appears in 1000 of these. Then, the inverse document frequency (idf) is calculated as IDF = log(10,000,000 / 1,000) = 4.\n",
    "\n",
    "Thus, the Tf-idf weight is the product of these quantities TF-IDF = 0.03 * 4 = 0.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018</th>\n",
       "      <th>champions</th>\n",
       "      <th>chennai</th>\n",
       "      <th>crowned</th>\n",
       "      <th>final</th>\n",
       "      <th>ipl</th>\n",
       "      <th>kings</th>\n",
       "      <th>returns</th>\n",
       "      <th>super</th>\n",
       "      <th>the</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333407</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.258921</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.438391</td>\n",
       "      <td>0.333407</td>\n",
       "      <td>0.258921</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.258921</td>\n",
       "      <td>0.438391</td>\n",
       "      <td>0.438391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.370954</td>\n",
       "      <td>0.48776</td>\n",
       "      <td>0.288079</td>\n",
       "      <td>0.48776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370954</td>\n",
       "      <td>0.288079</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.288079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.69903</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2018  champions   chennai  crowned     final       ipl     kings  \\\n",
       "0  0.333407    0.00000  0.258921  0.00000  0.438391  0.333407  0.258921   \n",
       "1  0.370954    0.48776  0.288079  0.48776  0.000000  0.370954  0.288079   \n",
       "2  0.000000    0.00000  0.412859  0.00000  0.000000  0.000000  0.412859   \n",
       "\n",
       "   returns     super       the       won  \n",
       "0  0.00000  0.258921  0.438391  0.438391  \n",
       "1  0.00000  0.288079  0.000000  0.000000  \n",
       "2  0.69903  0.412859  0.000000  0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import pandas as pd \n",
    "texts = [\"Chennai Super Kings won the final 2018 IPL\", \"Chennai Super Kings Crowned IPL 2018 Champions\",\"Chennai super kings returns\"] \n",
    "tfidf = TfidfVectorizer() \n",
    "features = tfidf.fit_transform(texts) \n",
    "pd.DataFrame(features.todense(),columns=tfidf.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-65ff36abb8cd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-65ff36abb8cd>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    TfidfVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                                                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "TfidfVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
